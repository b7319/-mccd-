import ccxt
import pandas as pd
from datetime import datetime, timezone
import streamlit as st
import pytz
import time
import base64
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed
from st_autorefresh import run as autorefresh_run

# åˆå§‹åŒ– gate.io API
api_key = st.secrets["GATEIO_API_KEY"]
api_secret = st.secrets["GATEIO_API_SECRET"]
exchange = ccxt.gateio({
    'apiKey': api_key,
    'secret': api_secret,
    'enableRateLimit': True,
    'timeout': 30000,
    'rateLimit': 1000
})

# é…ç½®å‚æ•°
CONFIG = {
    'refresh_interval': 60 * 1000,  # è‡ªåŠ¨åˆ·æ–°é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    'max_workers': 6,              # çº¿ç¨‹æ± å¤§å°
    'max_retries': 3,              # APIé‡è¯•æ¬¡æ•°
    'batch_size': 10               # æ¯æ‰¹å¤„ç†äº¤æ˜“å¯¹æ•°
}

# åˆå§‹åŒ– session state
def init_session_state():
    defaults = {
        'valid_signals': {tf: [] for tf in TIMEFRAMES},
        'shown_signals': {tf: set() for tf in TIMEFRAMES},
        'detection_round': 0,
        'new_signals_count': {tf: 0 for tf in TIMEFRAMES},
        'current_batch': 0,
        'audio_enabled': False,
        'pending_audio': False
    }
    for key, val in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = val

# äº¤æ˜“å‘¨æœŸé…ç½®
TIMEFRAMES = {
    '1m': {'interval': 60, 'max_bars': 500, 'cache_ttl': 45, 'window_size': 31},
    '5m': {'interval': 300, 'max_bars': 500, 'cache_ttl': 240, 'window_size': 31},
    '30m': {'interval': 1800, 'max_bars': 700, 'cache_ttl': 1500, 'window_size': 131},
    '4h': {'interval': 14400, 'max_bars': 700, 'cache_ttl': 14400, 'window_size': 131}
}

# éŸ³é¢‘å¤„ç†
@st.cache_data
def get_audio_base64():
    audio_file = open("alert.mp3", "rb")
    return base64.b64encode(audio_file.read()).decode('utf-8')

def audio_player():
    if st.session_state.pending_audio and st.session_state.audio_enabled:
        audio_html = f"""
        <audio autoplay>
            <source src="data:audio/mp3;base64,{get_audio_base64()}" type="audio/mp3">
        </audio>
        """
        st.components.v1.html(audio_html, height=0)
        st.session_state.pending_audio = False

# åˆå§‹åŒ–session state
init_session_state()

# ç•Œé¢ç»„ä»¶
def setup_ui():
    st.title('ğŸ“ˆ æ™ºèƒ½å¤šå‘¨æœŸè¶‹åŠ¿ç›‘æ§ç³»ç»Ÿ')
    st.markdown("### Gate.ioç°è´§å¸‚åœºå®æ—¶MAäº¤å‰ä¿¡å·æ£€æµ‹")
    
    with st.expander("âš™ï¸ ç³»ç»Ÿé…ç½®", expanded=True):
        st.session_state.audio_enabled = st.checkbox("å¯ç”¨å£°éŸ³æç¤º", value=st.session_state.audio_enabled)
        st.caption("é¦–æ¬¡ä½¿ç”¨éœ€è¦ç‚¹å‡»ä¸Šæ–¹å¤é€‰æ¡†å¯ç”¨å£°éŸ³æç¤º")
    
    st.sidebar.title("æ§åˆ¶é¢æ¿")
    st.sidebar.progress(st.session_state.current_batch/CONFIG['batch_size'], 
                       text="æ£€æµ‹è¿›åº¦")
    
    if st.sidebar.button("ğŸš¨ ç«‹å³åˆ·æ–°æ•°æ®"):
        st.session_state.current_batch = 0
        st.rerun()

# æ•°æ®å¤„ç†æ ¸å¿ƒé€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
# ... [ä¿æŒåŸæœ‰æ•°æ®å¤„ç†ã€ä¿¡å·æ£€æµ‹ç­‰æ ¸å¿ƒé€»è¾‘ä¸å˜] ...

# åˆ†æ‰¹å¤„ç†å‡½æ•°
def process_batch(symbols_batch):
    with ThreadPoolExecutor(max_workers=CONFIG['max_workers']) as executor:
        futures = []
        for symbol in symbols_batch:
            for timeframe in TIMEFRAMES:
                futures.append(executor.submit(process_symbol_task, symbol, timeframe))
        
        for future in as_completed(futures):
            symbol, timeframe, signal = future.result()
            if signal:
                handle_new_signal(signal)

def handle_new_signal(signal):
    tf = signal['timeframe']
    signal_id = signal['signal_id']
    if signal_id not in st.session_state.shown_signals[tf]:
        st.session_state.valid_signals[tf].append(signal)
        st.session_state.shown_signals[tf].add(signal_id)
        st.session_state.new_signals_count[tf] += 1
        st.session_state.pending_audio = True

# ä¸»æ£€æµ‹æµç¨‹
def main_detection_cycle():
    symbols = get_top_valid_symbols()
    if not symbols:
        st.error("æ— æ³•è·å–äº¤æ˜“å¯¹åˆ—è¡¨")
        return
    
    total_batches = len(symbols) // CONFIG['batch_size'] + 1
    start = st.session_state.current_batch * CONFIG['batch_size']
    end = start + CONFIG['batch_size']
    current_batch = symbols[start:end]
    
    process_batch(current_batch)
    
    if end < len(symbols):
        st.session_state.current_batch += 1
        st.rerun()
    else:
        st.session_state.current_batch = 0
        st.session_state.detection_round += 1
        autorefresh_run(interval=CONFIG['refresh_interval'], limit=100)

# ç»“æœå±•ç¤º
def display_results():
    tabs = st.tabs([f"{tf.upper()}å‘¨æœŸ" for tf in TIMEFRAMES])
    for idx, tf in enumerate(TIMEFRAMES):
        with tabs[idx]:
            if st.session_state.valid_signals[tf]:
                for signal in st.session_state.valid_signals[tf]:
                    st.success(f"""
                    ğŸš© **äº¤æ˜“å¯¹**: {signal['symbol']}  
                    â° **æ—¶é—´æ¡†æ¶**: {tf.upper()}  
                    ğŸ”” **ä¿¡å·ç±»å‹**: {signal['signal_type']}  
                    ğŸ“… **ä¿¡å·æ—¶é—´**: {signal['condition_time']}
                    """)
            else:
                st.info("å½“å‰å‘¨æœŸæš‚æ— æœ‰æ•ˆä¿¡å·")

def main():
    setup_ui()
    audio_player()
    
    with st.spinner("ğŸ” æ­£åœ¨æ‰«æå¸‚åœºæœºä¼š..."):
        main_detection_cycle()
    
    display_results()
    
    st.sidebar.markdown(f"**æ£€æµ‹è½®æ¬¡**: {st.session_state.detection_round}")
    st.sidebar.markdown("**æœ€æ–°ä¿¡å·ç»Ÿè®¡**")
    for tf in TIMEFRAMES:
        st.sidebar.metric(f"{tf.upper()}å‘¨æœŸ", 
                         st.session_state.new_signals_count[tf])

if __name__ == "__main__":
    main()
